\chapter{Predictable Execution and Software for Analysis}\label{chp4:predictable_execution} 
A prerequisite to analysis of acoustic fingerprints is that you have some idea of what you are recording, and thus be able to look at the correlation between what is observed, and what was going on at the time.
In our case this means that we need to know what is going on in the CPU during the timespan of our recordings.
If we possess this knowledge, we should be more able draw conclusions regarding the correlation between what is observed in the acoustic fingerprint and distinct CPU activity.
This chapter will describe how we force predictable CPU activity, and also how we tailor the software run during the recordings for different architectures to achieve comparable results.

\section{Selection of Test Cases}
We will use several test cases, where the aim is to gradually record more and more subtle variations in CPU activity, and use this as a basis for our acoustic analysis.
We will start by oscillating between abnormally high CPU loads and a minimal load, and eventually we will try to distinguish between the execution of the repeated execution of different distinct microinstructions.

The following sections will in detail describe the different utilities we use to inflict this CPU behavior, and how we wrap the different tokens of predictable executions in a deterministically looped pattern to be used in later analysis, thus relating the CPU behavior to the time domain. 
Additionally, we will note our expectations, being a description of the expected impact our tests should have on the acoustic fingerprint.


\section{CPU load}\label{chp4:sec:cpu_load}

Our first choice of distinguishable CPU activity is in the form of a CPU burn utility. 
The idea is that when no programs are running, save the operating system, the activity level of the CPU us low. 
However, if the user executes a program that will make all cores on the CPU work at close to their full capacity, the internal activity of the CPU will change drastically as a consequence of the increased load.

To achieve this, we installed the cpuburn collection which can be installed using the debian package manager using
apt-get install cpuload. 

To be able to relate this to the time domain, we will execute the CPU burn tool according to the algorithm described in \autoref{lst:cpuburn_loop_utility}.

\begin{lstlisting}[language=BASH, caption={Mapping execution to the time domain: CPU Burn Utility}, label={lst:cpuburn_loop_utility}]
for i in {1..3}
do
	# burn all cores for 2 seconds
	sleep 1
done
\end{lstlisting}

This simple loop will let us search for distinct one second intervals in the acoustic fingerprints, as the CPU will operate at close to full capacity, then sleep for a second each, representing the heavy load state and the idle state.
By recording while executing this utility we hope to be able to distinguish between the two states, and to be able to observe a repeating pattern with a period of \(1\) second.

For the Raspberry Pi, we used the used the sysbench\cite{url:sysbench_wiki} package to generate cpu load. 
This package has a benchmarking tool for ARM CPUs, which was used to generate the CPU load. 

\section{Microinstructions}\label{chp4:sec:microinstructions}

\subsection{Mapping to Time Domain}\label{chp4:sec:mapping_to_time_domain}
With our next test utility we want to look at the acoustic fingerprint of different microinstructions. 
The original \todo{Cite} research suggests that looping through a set of microinstructions that are repeated over an observable period of time, should result in a distinguishable acoustic fingerprint for each instruction.
Thus we want an utility that lets us repeat this experiment. 

Since we are using sampling frequencies in the kHz-range and processors operate on frequencies in the GHz-range, it is futile to try to capture the fingerprint of a single clock cycle representing the execution of a specific microinstruction. 
This limitation can be dealt with by repeating the same instruction for a longer timespan, such that every \(\Delta t\) seconds, a new instruction will start executing.
With \(n\) different instructions, one pass through all instructions will take \(T = n \times \Delta t\) seconds, and we want to repeat the loop more than once, so that we can look not only for a change from one lastingly stable signal every \(\Delta t\) seconds, but also a repeating pattern every \(T\) seconds.

The microinstruction repetition pattern used in this utility is described in detail in \autoref{lst:microinstruction_loop_utility}

\begin{lstlisting}[language=BASH, caption={Mapping execution to the time domain: Microinstruction loop utility.}, label={lst:microinstruction_loop_utility}]
for i in {1..3}
do
	for j in {1..n}
	do
		# run instruction j for 0.33 seconds
	done
done
\end{lstlisting}

The CPU operation will will loop are the MUL, ADD and NOP microinstructions as well as memory access with forced L1 and L2 cache miss. 
The following subsections will go into further detail on how timely and predictable execution was achieved in all four cases for both ARM and x86 architectures.

\subsection{Memory Access and Predictable Cache Miss}
\label{chp4:subsec:MEM_operation}

The memory dereference (MEM) operation's performance with regard to speed depends heavily on if the target is cached or not. 
If cache hit occurs in the L1 or L2 cache, the lookup time is much lower than if the value has to be read from the RAM.
We want to achieve is a program where the CPU constantly has to go all the way to the RAM to fetch values.
As it turns out, list access loads and stride access loads are a good generator of cache misses~\cite{DBLP:conf/micro/OzawaKN95}.
Unfortunately, modern processors are putting great effort into predict memory accesses; constant stride load patterns can easily be detected in hardware~\cite{DBLP:journals/taco/LeeKV12}, and the data can be prefetched causing few to zero cache misses.
For this reason, we cannot rely on simple mechanisms such as sequential memory access using a stride bigger than the size of the cache.

Luckily the existence of hardware performance counters allow us to evaluate our approach to the MEM operation. Performance counters are a set of hardware registers that can be used to count events such as cache misses during the execution of a program, without impacting the execution~\cite{url:perf_wiki}.

We make two programs; \(A\) which randomly resolves \(n = 1000\) indexes in an array that is several orders of magnitude bigger than the L2 cache of the targeted CPU; and \(B\) which is identical to \(A\), save the fact that it deterministically resolves subsequent indexes.
During the course of execution, \(A\) should to suffer approximately \(k+n\) cache misses, while \(B\) should suffer only \(k\), due to successful stride prediction. 
If this condition holds, we can argue that the program \(A\) should cause \(n\) more cache misses than \(B\) and thus reliably executes the MEM operation. 

\todo{Make inverse CDF and fix dotted line. Do flat lower limit removal in data set.}
\begin{figure}
    \centering
    %\resizebox{\linewidth}{!}{
        \begin{tikzpicture}
            \begin{axis}[
                title={Cache Miss Probability Distribution},
                xlabel={$\Delta C$},
                ylabel={$p$},
                legend pos=south east,
                legend style={font=\tiny},
                grid style=dashed,
                ymajorgrids=true,
                ymode=log,
                %ymin=0, ymax=1,
            ]
            \addplot table [smooth, dotted, mark=none, y=p, x=D430, col sep=comma] {data/mem-benchmark-cdf.csv};
            \addlegendentry{Dell Latitude D430}
            \addplot table [dashed, mark=none, y=p, x=T60p, col sep=comma] {data/mem-benchmark-cdf.csv};
            \addlegendentry{Lenovo Thinkpad T60p}
            \end{axis}
        \end{tikzpicture}
    %}
    \caption{Probability \(p\) of observing less than \(\Delta C\) cache misses when running the random lookup procedure.}
    \label{fig:mem_benchmark}
\end{figure}

% \begin{tikzpicture}
%         \begin{axis}
%                 \addplot[smooth,mark=o,dotted]
%                         plot coordinates {(1,1) (2,2) (3,2)};
%                 \addplot[mark=o]
%                         plot coordinates {(1,2) (2,3) (3,5)};
%         \end{axis}
% \end{tikzpicture} 


We ran \(A\) and \(B\) \(1000\) times, measuring the number of cache misses \(c_A\) and \(c_B\) suffered by \(A\) and \(B\).
Then we look at the difference in cache misses \(\Delta C_i = c_{A_i} - c_{B_i}\) for every run \(i \in [1, 1000]\). 
The results are given in \autoref{fig:mem_benchmark}, and clearly show that the probability of observing the expected \(\Delta C\) close to \(1000\) is about \(90\%\), thus our condition holds.
Our MEM utility program is successfully bypassing the CPUs best efforts of hardware prefetching and stride prediction.

\subsection{MUL, ADD and NOP execution on Different Architectures}
\label{chp4:subsec:MUL_ADD_NOP_instructions}

The three native microinstructions that we look at are MUL, ADD, and NOP. 
To achieve the repeated execution of this these instructions over time, we repeat the assembly code for each instruction \(1000\) times in each loop pass, thus reducing the impact from the microinstructions used to perform the actual loop. 
This way we can know that our targeted instruction is what is actually executed by our program, and that the count of other instructions occurring is only a fraction of the count of the instruction whom we are trying to force.

\newsavebox{\MEMfigure}
	\begin{lrbox}{\MEMfigure}%store first listing
	\begin{lstlisting}[language={[x86masm]Assembler}]
		mov $0, %eax;
		mov $1, $ebx;
		mul %eax;
	\end{lstlisting}
\end{lrbox}

\newsavebox{\ADDfigure}
	\begin{lrbox}{\ADDfigure}%store first listing
	\begin{lstlisting}[language={[x86masm]Assembler}]
		mov $0, %eax;
		mov $1, $ebx;
		add %ebx, %eax;
	\end{lstlisting}
\end{lrbox}

\begin{figure}[h]
    \begin{subfigure}{0.5\textwidth}
        \centering
        \usebox{\MEMfigure}
        \caption{MEM}
    \end{subfigure}
    \begin{subfigure}{0.5\textwidth}
        \centering
        \usebox{\ADDfigure}
        \caption{ADD}
    \end{subfigure}
	\caption{The setup code for the NOP and MEM instructions. The instruction on line number 3 is repeated \(1000\) times.}
	\label{lst:x86_add_mem}
\end{figure}

The NOP instruction was simply rep; nop; repeated \(1000\) times; for the MEM and ADD instructions, see \autoref{lst:x86_add_mem}. 


\subsection{Expectations regarding acoustic fingerprints}

Our finished utility is combining the MEM operation, as described in \autoref{chp4:subsec:MEM_operation} and the MUL, ADD and NOP-loops which are described in \autoref{chp4:subsec:MUL_ADD_NOP_instructions}.
Executing the four operations in the pattern given in \autoref{lst:microinstruction_loop_utility}, we are able to look for for repeating patterns in the acoustic fingerprint of the CPUs executing the utility.
More precisely, we will look for periodic patterns that represent an interval in time \(t\) of \(0.33\) seconds. 
If we see such patterns with a period of \(4t = 1.33\) seconds, they could possibly be caused by the fact that the CPU is performing the operations caused by our utility, and argue that we are in fact able to distinguish between such low level operations based purely on the acoustic fingerprint. 



\section{Decryption}\label{chp4:sec:decryption}

The original research clearly states that it is possible to distinguish when a decryption with a 4096-bit RSA key is used, and also differentiate between when the CPU is using \(p\) and \(q\).
At first glance we want to distinguish when a decryption is done, and hopefully when \(p\) and \(q\) are used. 
We use the GnuPG 1.4.15~\cite{url:GnuPG_1.4.15} library as the original paper exploits some vulnerabilities found in GnuPG versions up to 1.4.15. 

Before our decryption is done, we are encrypting a \(sound.wav\) file of the size 4.2MB with a 4096-bit RSA key, seen in \autoref{lst:encryption_rsakey}. The key is generated in the Thunderbird extension Enigmail and is related to an email account.
Our choice of encryption/decryption method, key-size and key generation is due to the chosen cipher text attack related to the original research, see 1.1 Chosen Chiphertexts by e-mail in~\cite{DBLP:conf/crypto/GenkinST14}. 
\begin{lstlisting}[
language=BASH, 
caption={Encryption with a 4096-bit RSA key.}, 
label={lst:encryption_rsakey}]
gpg --output sound.gpg --encrypt --recipient bmanharry@gmail.com sound.wav
\end{lstlisting}

To be able to relate the decryption to the time domain, we will execute the decryption according to the algorithm described in \autoref{lst:decryption_loop_utility}

\begin{lstlisting}[
language=BASH, 
caption={Mapping execution to the time domain: Decryption loop utility.}, 
label={lst:decryption_loop_utility}]
for i in {1..3}
do
    sleep 1
    gpg --output tmp/sound.wav --decrypt sound.gpg
done
\end{lstlisting}

The loop in our decryption utility will easily let us search for a pattern; one second sleep followed by a decryption. 
The decryption of the \(sound.gpg\) file will probably extend over a different amount of time on different computer, i.e. different CPU. 
